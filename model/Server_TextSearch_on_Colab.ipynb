{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXoLBFnJ5EeO",
        "outputId": "c4bcc505-c1c8-4ca3-ef8f-5c8fe79875f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B7UcrPpUI1q0",
        "outputId": "3b9f696d-7438-4577-aeb6-c9198f089244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.1+cu121)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (10.4.0)\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: mypy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (7.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.8.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.13.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (6.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.10.0.84)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (16.1.0)\n",
            "Requirement already satisfied: torchmetrics==0.7.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.7.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.44.2)\n",
            "Requirement already satisfied: deepspeed==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.4.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (2.0.8)\n",
            "Requirement already satisfied: pycocoevalcap in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.2)\n",
            "Requirement already satisfied: torchscale==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.2.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.3->-r requirements.txt (line 17)) (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.3->-r requirements.txt (line 17)) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (4.66.5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (5.9.5)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: fairscale==0.4.0 in /usr/local/lib/python3.10/dist-packages (from torchscale==0.2.0->-r requirements.txt (line 22)) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (3.21.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mypy->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->-r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (2024.8.30)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 13)) (0.2.13)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.19.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/unilm/beit3 && pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cf5hvWb2EzvN",
        "outputId": "ee230f3b-6be3-40c2-db02-1516d4cc617c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask_cors) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install pyngrok\n",
        "!pip install pymongo\n",
        "!pip install flask_cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "o3JcTvoU6JWV"
      },
      "outputs": [],
      "source": [
        "# !pip install salesforce-lavis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEur21-wE2Dd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import concurrent.futures\n",
        "import time\n",
        "import re\n",
        "from IPython.display import display, Image as IPImage\n",
        "import re\n",
        "from pymongo import InsertOne, MongoClient\n",
        "from pymongo.errors import ConnectionFailure\n",
        "from pyngrok import ngrok, conf\n",
        "from flask import Flask, jsonify, request\n",
        "from flask_cors import CORS, cross_origin\n",
        "import threading\n",
        "import sys\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A-vndGjgE73u"
      },
      "outputs": [],
      "source": [
        "# from lavis.models import load_model_and_preprocess\n",
        "# import torch\n",
        "# device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "# model, _, txt_processors = load_model_and_preprocess(name=\"blip2_feature_extractor\", model_type=\"pretrain\", is_eval=True, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YY5J4yEKLvL"
      },
      "outputs": [],
      "source": [
        "def get_sentencepiece_model_for_beit3(model_path):\n",
        "    from transformers import XLMRobertaTokenizer\n",
        "    return XLMRobertaTokenizer(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHtv52mPKHdL",
        "outputId": "11ea4fda-281e-476e-e6be-ac6394be2e63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "<ipython-input-7-01a7817dc1b6>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_weight_path)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BEiT3ForRetrieval(\n",
              "  (beit3): BEiT3(\n",
              "    (text_embed): TextEmbedding(64010, 768)\n",
              "    (vision_embed): VisionEmbedding(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "      (embed_positions): MutliwayEmbedding(\n",
              "        (A): PositionalEmbedding(579, 768)\n",
              "        (B): PositionalEmbedding(1024, 768)\n",
              "      )\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x EncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (v_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (q_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (out_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (inner_attn_ln): MultiwayNetwork(\n",
              "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (self_attn_layer_norm): MultiwayNetwork(\n",
              "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "          (ffn): MultiwayNetwork(\n",
              "            (A): FeedForwardNetwork(\n",
              "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (B): FeedForwardNetwork(\n",
              "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): MultiwayNetwork(\n",
              "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): MultiwayNetwork(\n",
              "        (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (language_head): Linear(in_features=768, out_features=768, bias=False)\n",
              "  (vision_head): Linear(in_features=768, out_features=768, bias=False)\n",
              "  (criterion): ClipLoss()\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"/content/drive/MyDrive/beit3-retrieval-pth/beit3.spm\"\n",
        "tokenizer = get_sentencepiece_model_for_beit3(model_path=model_path)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "sys.path.append('/content/drive/MyDrive/unilm/beit3/') ## /content/drive/MyDrive/unilm/beit3/\n",
        "from unilm.beit3.modeling_finetune import beit3_base_patch16_384_retrieval\n",
        "model_weight_path = '/content/drive/MyDrive/beit3-retrieval-pth/beit3_base_patch16_384_f30k_retrieval.pth'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = beit3_base_patch16_384_retrieval(pretrained=True)\n",
        "checkpoint = torch.load(model_weight_path)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiRGxagkE963"
      },
      "outputs": [],
      "source": [
        "# def encode_text_query(text_query, txt_processors, model, device):\n",
        "#     \"\"\"\n",
        "#     Encode a text query into a vector using text processors and model.\n",
        "\n",
        "#     Args:\n",
        "#         text_query (str): The text query to be encoded.\n",
        "#         txt_processors (dict): Dictionary containing text processors.\n",
        "#         model (object): Model used for encoding the text.\n",
        "#         device (torch.device): Device to which the tensors should be moved.\n",
        "\n",
        "#     Returns:\n",
        "#         np.array: Encoded text vector.\n",
        "#     \"\"\"\n",
        "#     # Process the text query\n",
        "#     text_processed = txt_processors[\"eval\"](text_query)\n",
        "\n",
        "#     # Encode the text query into a vector\n",
        "#     sample = {\"image\": [], \"text_input\": text_processed}\n",
        "#     text_embedding = model.extract_features(sample, mode=\"text\").text_embeds[:, 0, :].cpu().detach().numpy().flatten()\n",
        "#     text_embedding = text_embedding / np.linalg.norm(text_embedding)\n",
        "\n",
        "#     return text_embedding\n",
        "\n",
        "def get_frame_ids_from_json(json_file_path):\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "        return [item['frame_id'] for item in data]\n",
        "\n",
        "def faiss_read_index(faiss_index_path):\n",
        "    index = faiss.read_index(faiss_index_path)\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wJg33pzFF54"
      },
      "outputs": [],
      "source": [
        "def load_image(frame_path, index):\n",
        "        # \"\"\"Helper function to load image and title.\"\"\"\n",
        "        frame_path = frame_path.replace('/AIO_Chef/L10-11-12', '')\n",
        "        folder_name = os.path.basename(os.path.dirname(frame_path))\n",
        "        file_name = os.path.basename(frame_path)\n",
        "        frame_title = f\"{folder_name}/{file_name}\".replace('_', '/').replace('keyframes/filtered', '').replace('frame', '').replace('.jpg', '').replace('//', '').replace('unzipped', '/')\n",
        "        frame_title = str(index + 1) + '. ' + frame_title\n",
        "        with Image.open(frame_path) as img:\n",
        "          return np.array(img), frame_title\n",
        "\n",
        "def search_faiss_index(query_vector, index, frame_paths, k=5):\n",
        "    \"\"\"\n",
        "    Search for similar frames in the FAISS index and return the frame paths.\n",
        "\n",
        "    Parameters:\n",
        "    - query_vector: The query vector to search for.\n",
        "    - index: The FAISS index.\n",
        "    - frame_paths: List of frame paths.\n",
        "    - k: Number of nearest neighbors to return.\n",
        "\n",
        "    Returns:\n",
        "    - A list of tuples (frame_path, distance) for the nearest neighbors.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform search\n",
        "    D, I = index.search(np.array([query_vector], dtype='float32'), k)\n",
        "\n",
        "    execution_time = time.time() - start_time\n",
        "    print(f\"Execution time for search: {execution_time:.4f} seconds\")\n",
        "\n",
        "    # Collect results\n",
        "    results = [(frame_paths[I[0][i]], D[0][i], i) for i in range(k) if 0 <= I[0][i] < len(frame_paths)]\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAs5B1TZJdks"
      },
      "outputs": [],
      "source": [
        "# BEIT3\n",
        "def to_text_tokens(text, tokenizer, max_len = 64):\n",
        "\n",
        "    tokens_orig = tokenizer.tokenize(text)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens_orig)\n",
        "    tokens = token_ids\n",
        "\n",
        "    if len(tokens) > max_len - 2:\n",
        "        tokens = tokens[:max_len - 2]\n",
        "\n",
        "    tokens = [tokenizer.bos_token_id] + tokens[:] + [tokenizer.eos_token_id]\n",
        "    num_tokens = len(tokens)\n",
        "    padding_mask = [0] * num_tokens + [1] * (max_len - num_tokens)\n",
        "    tokens_true = tokens + [tokenizer.pad_token_id] * (max_len - num_tokens)\n",
        "\n",
        "    padding_mask_tensor = torch.tensor(padding_mask).reshape(1, -1).to(device)\n",
        "    token_ids_tensor = torch.tensor(tokens_true).reshape(1, -1).to(device)\n",
        "\n",
        "    return token_ids_tensor, padding_mask_tensor\n",
        "\n",
        "def calc_text_embedding(text, tokenizer):\n",
        "    text_tokens, padding_mask = to_text_tokens(text, tokenizer)\n",
        "    text_embedding = model(text_description=text_tokens, padding_mask=padding_mask, only_infer=True)\n",
        "    return text_embedding[1]\n",
        "def encode_text_query(text_query, tokenizer, model, device):\n",
        "    \"\"\"\n",
        "    Encode a text query into a vector using a custom tokenizer and model.\n",
        "\n",
        "    Args:\n",
        "        text_query (str): The text query to be encoded.\n",
        "        tokenizer (object): Tokenizer used for text processing.\n",
        "        model (object): Pretrained model used for encoding the text.\n",
        "        device (torch.device): Device to which the tensors should be moved.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Encoded text vector.\n",
        "    \"\"\"\n",
        "    # Calculate text embedding using the custom calc_text_embedding function\n",
        "    text_embedding = calc_text_embedding(text_query, tokenizer).cpu().detach().numpy().flatten()\n",
        "\n",
        "    # Normalize the embedding vector\n",
        "    text_embedding = text_embedding / np.linalg.norm(text_embedding)\n",
        "\n",
        "    return text_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUzfNmUOFM5W"
      },
      "outputs": [],
      "source": [
        "def extract_frame_number(filename):\n",
        "    \"\"\"\n",
        "    Extract frame number from filename like 'frame_22849.jpg'.\n",
        "    \"\"\"\n",
        "    match = re.search(r'frame_(\\d+)\\.jpg$', filename)\n",
        "    return int(match.group(1)) if match else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwQALFzOHRuc"
      },
      "outputs": [],
      "source": [
        "frame_paths = get_frame_ids_from_json('/content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/qualifying_round_frame_ids (1).json')\n",
        "index = faiss_read_index('/content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/qualifying_round_frame_embeddings_beit3.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRTo8plkFVK8",
        "outputId": "e67decaa-8328-4d46-ab25-7b2e90a44d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time for search: 0.3055 seconds\n",
            "[('L09_V007_11237', 0.5762359, 0), ('L09_V007_15011', 0.5746697, 1), ('L09_V007_15029', 0.5731076, 2), ('L09_V007_14961', 0.57235324, 3), ('L06_V026_22467', 0.5711816, 4), ('L06_V026_22448', 0.56980395, 5), ('L06_V026_22505', 0.56895995, 6), ('L09_V007_14977', 0.56441915, 7), ('L06_V026_22525', 0.5563766, 8), ('L09_V007_11217', 0.5550802, 9)]\n"
          ]
        }
      ],
      "source": [
        "# Search example\n",
        "txt_query = 'Two people wearing blue protective suits are carrying a victim on a stretcher'\n",
        "text_embedding = encode_text_query(txt_query, tokenizer, model, device)\n",
        "results = search_faiss_index(text_embedding, index, frame_paths, k=10)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNXYl6Ez_cM_",
        "outputId": "7d7e95fb-d150-416e-c546-e055e738f644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to MongoDB\n"
          ]
        }
      ],
      "source": [
        "mongo_uri = 'mongodb+srv://cokain:2zE5rhXbasjtlPa8@vbs.hoqme.mongodb.net/'\n",
        "try:\n",
        "    client = MongoClient(mongo_uri)\n",
        "    db = client['frames']\n",
        "    collection = db['links']\n",
        "    print(\"Connected to MongoDB\")\n",
        "except ConnectionFailure:\n",
        "    print(\"Could not connect to MongoDB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_8jU6Tn7u-j"
      },
      "outputs": [],
      "source": [
        "def extract_image_info(file_path):\n",
        "    \"\"\"\n",
        "    Extract L, V and sequence number from file path\n",
        "\n",
        "    :param file_path: google drive file path\n",
        "    :return: dict of L, V and sequence number. If not found, return None\n",
        "    \"\"\"\n",
        "    lv_pattern = r'L(\\d+)_V(\\d+)'\n",
        "\n",
        "    seq_pattern = r'frame_(\\d+)\\.jpg'\n",
        "\n",
        "    lv_match = re.search(lv_pattern, file_path)\n",
        "    seq_match = re.search(seq_pattern, file_path)\n",
        "\n",
        "    if lv_match and seq_match:\n",
        "        # return {\n",
        "        #     'L': int(lv_match.group(1)),\n",
        "        #     'V': int(lv_match.group(2)),\n",
        "        #     'sequence_number': int(seq_match.group(1))\n",
        "        # }\n",
        "        return f'L{int(lv_match.group(1)):02}_V{int(lv_match.group(2)):03}_{int(seq_match.group(1)):05}'\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXbafaWC_X22"
      },
      "outputs": [],
      "source": [
        "def get_image(image_ids):\n",
        "    return list(collection.find({\"image_id\": {\"$in\": image_ids}}, {\"_id\": 0}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8qxg-lm8cCU"
      },
      "outputs": [],
      "source": [
        "# Create a simple Flask app\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Hello from AIO_Chef!\"\n",
        "\n",
        "@app.route('/search', methods = [\"POST\"])\n",
        "@cross_origin()\n",
        "def search():\n",
        "    json_data = request.get_json()\n",
        "    query = json_data['query']\n",
        "    request_model = json_data['model']\n",
        "    limit = json_data['limit']\n",
        "\n",
        "    print(query, request_model, limit)\n",
        "\n",
        "    text_embedding = encode_text_query(query, tokenizer, model, device)\n",
        "    results = search_faiss_index(text_embedding, index, frame_paths, k=limit)\n",
        "    img_ids_with_scores = [(result[0], result[1]) for result in results]\n",
        "    images = get_image([img_id for img_id, _ in img_ids_with_scores])\n",
        "    image_links = {img['image_id']: img['google_drive_link'] for img in images}\n",
        "    image_watch_urls = {\n",
        "            img[\"image_id\"]: img[\"watch_url\"]\n",
        "            for img in images\n",
        "        }\n",
        "    image_frame_stamps = {\n",
        "            img[\"image_id\"]: img[\"frame_stamp\"]\n",
        "            for img in images\n",
        "        }\n",
        "\n",
        "    img_list = [\n",
        "    {\n",
        "        \"image_id\": img_id,\n",
        "        \"link\": image_links.get(img_id, \"\"),\n",
        "        \"score\": float(score),\n",
        "        \"frame_stamp\":  image_frame_stamps.get(img_id, \"\"),\n",
        "        \"watch_url\": image_watch_urls.get(img_id, \"\")\n",
        "    }\n",
        "      for img_id, score in img_ids_with_scores\n",
        "    ]\n",
        "    img_list.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    return jsonify({\"item_count\": len(img_list), \"frames\": img_list})\n",
        "\n",
        "@app.route('/neighbor', methods = [\"POST\"])\n",
        "@cross_origin()\n",
        "def neighbor_search():\n",
        "    json_data = request.get_json()\n",
        "    frame_id = json_data['id']\n",
        "    limit = json_data['limit']\n",
        "\n",
        "    # Kiểm tra format frame_id\n",
        "    match = re.match(r'L(\\d+)_V(\\d+)_(\\d+)', frame_id)\n",
        "    if not match:\n",
        "        raise ValueError(\"Invalid frame_id format\")\n",
        "\n",
        "    l, v, sequence_number = map(int, match.groups())\n",
        "\n",
        "    # Tìm frame hiện tại\n",
        "    current_frame = collection.find_one({\"image_id\": frame_id})\n",
        "    if not current_frame:\n",
        "        raise ValueError(f\"No frame found with id {frame_id}\")\n",
        "\n",
        "    # Tìm các frame trước đó\n",
        "    previous_frames = list(collection.find(\n",
        "        {\"l\": l, \"v\": v, \"sequence_number\": {\"$lt\": sequence_number}},\n",
        "        {\"image_id\": 1, \"sequence_number\": 1, \"_id\": 0}\n",
        "    ).sort(\"sequence_number\", -1).limit(limit))\n",
        "\n",
        "    # Tìm các frame sau đó\n",
        "    next_frames = list(collection.find(\n",
        "        {\"l\": l, \"v\": v, \"sequence_number\": {\"$gt\": sequence_number}},\n",
        "        {\"image_id\": 1, \"sequence_number\": 1, \"_id\": 0}\n",
        "    ).sort(\"sequence_number\", 1).limit(limit))\n",
        "\n",
        "    # Gộp và loại bỏ trùng lặp bằng set\n",
        "    unique_frames = []\n",
        "    seen_image_ids = set()\n",
        "\n",
        "    for frame in previous_frames + next_frames:\n",
        "        if frame[\"image_id\"] not in seen_image_ids:\n",
        "            unique_frames.append(frame)\n",
        "            seen_image_ids.add(frame[\"image_id\"])\n",
        "\n",
        "    # Giới hạn tổng số lượng frame trả về\n",
        "    results = unique_frames[:limit*2]\n",
        "\n",
        "    # Lấy thông tin link hình ảnh từ danh sách kết quả\n",
        "    img_list = [{\n",
        "        \"image_id\": img[\"image_id\"],\n",
        "        \"link\": img[\"google_drive_link\"],\n",
        "        \"watch_url\": img[\"watch_url\"],\n",
        "        \"frame_stamp\": img[\"frame_stamp\"]\n",
        "        } for img in get_image([img[\"image_id\"] for img in results])]\n",
        "\n",
        "    return jsonify({\"item_count\": len(img_list), \"frames\": img_list})\n",
        "\n",
        "@app.route('/getById', methods = [\"POST\"])\n",
        "@cross_origin()\n",
        "def get_img_by_id():\n",
        "    json_data = request.get_json()\n",
        "    frame_id = json_data['id']\n",
        "    img = get_image([frame_id])\n",
        "\n",
        "    return jsonify({\"item_count\": len(img), \"frames\": img})\n",
        "\n",
        "\n",
        "# Function to run the Flask app\n",
        "def run_flask():\n",
        "    app.run(port=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fCNpmcpO8gZx"
      },
      "outputs": [],
      "source": [
        "# conf.get_default().auth_token = \"2mOqhQcSnbbYhkfCMidP4Mqrx8e_21rYHbQprP4HVABgcXhky\"\n",
        "# connection_string = ngrok.connect(\"22\", \"tcp\").public_url\n",
        "\n",
        "# ssh_url, port = connection_string.strip(\"tcp://\").split(\":\")\n",
        "# print(f\" * ngrok tunnel available, access with ssh root@{ssh_url} -p{port}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97wdSLSm8hCJ",
        "outputId": "bbf5e165-1cb1-4f38-f23b-b37a8a2d058b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ngrok tunnel available at: https://b561-35-196-211-155.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"2mOqhQcSnbbYhkfCMidP4Mqrx8e_21rYHbQprP4HVABgcXhky\")\n",
        "\n",
        "connection_string = ngrok.connect(5000)\n",
        "\n",
        "public_url = connection_string.public_url\n",
        "\n",
        "print(f\"Ngrok tunnel available at: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojb3UdR49P9d",
        "outputId": "78c7869d-f120-438b-f983-d5fc0189368e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:00:59] \"OPTIONS /search HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a man and a dog blip2_feature_extractor 100\n",
            "Execution time for search: 0.7638 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:01:02] \"POST /search HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:03:41] \"OPTIONS /neighbor HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:03:41] \"OPTIONS /neighbor HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:03:42] \"POST /neighbor HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Oct/2024 04:03:42] \"POST /neighbor HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "run_flask()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}