{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eflkG3B3uGU1",
        "outputId": "c31528b1-9803-4650-cd63-346ed36fc9eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNfp4ZiuuRLy",
        "outputId": "4f6b4860-44b0-4953-cdf6-49f66784e425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.1+cu121)\n",
            "Collecting timm==0.4.12 (from -r requirements.txt (line 3))\n",
            "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (10.4.0)\n",
            "Collecting blobfile (from -r requirements.txt (line 5))\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting mypy (from -r requirements.txt (line 6))\n",
            "  Downloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (7.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.8.0)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 11))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.13.1)\n",
            "Collecting ftfy (from -r requirements.txt (line 13))\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.10.0.84)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (14.0.2)\n",
            "Collecting torchmetrics==0.7.3 (from -r requirements.txt (line 17))\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.44.2)\n",
            "Collecting deepspeed==0.4.0 (from -r requirements.txt (line 19))\n",
            "  Downloading deepspeed-0.4.0.tar.gz (444 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.6/444.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (2.0.8)\n",
            "Collecting pycocoevalcap (from -r requirements.txt (line 21))\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting torchscale==0.2.0 (from -r requirements.txt (line 22))\n",
            "  Downloading torchscale-0.2.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics==0.7.3->-r requirements.txt (line 17))\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.3->-r requirements.txt (line 17)) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (4.66.5)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 11))\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ninja (from deepspeed==0.4.0->-r requirements.txt (line 19))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (5.9.5)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (1.16.0)\n",
            "Collecting fairscale==0.4.0 (from torchscale==0.2.0->-r requirements.txt (line 22))\n",
            "  Downloading fairscale-0.4.0.tar.gz (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->-r requirements.txt (line 5))\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (4.9.4)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->-r requirements.txt (line 6))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->-r requirements.txt (line 6)) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 9)) (2024.8.30)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 13)) (0.2.13)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.19.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 20)) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.2/398.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "Building wheels for collected packages: deepspeed, torchscale, fairscale\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.4.0-py3-none-any.whl size=447153 sha256=17927848e09290f97d59ebbb1323142624b0efa56de203d4e01ed41210aa99e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/6b/3e/5df4da896296e9e89f03684bdaa753f547b43fbe14cfde1d40\n",
            "  Building wheel for torchscale (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchscale: filename=torchscale-0.2.0-py3-none-any.whl size=59729 sha256=b15708d586ea540e96a7e2a1724af7a3b82fe2dca7d2a200d13bc55690cf4145\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/cb/2a/124969b43eaf0fb551b75d4acbeb211cb73b6bd7762f5812ab\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239917 sha256=8b1a01f0d33c87ac087c85ba870a612dec080c3c4b7d0d87e0075b4545f960a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/3d/e9/3995d67ff23a09f72bba6380efb35ba97091c7932748884c41\n",
            "Successfully built deepspeed torchscale fairscale\n",
            "Installing collected packages: ninja, tensorboardX, pyDeprecate, pycryptodomex, mypy-extensions, ftfy, mypy, blobfile, torchmetrics, fairscale, timm, pycocoevalcap, deepspeed, torchscale\n",
            "Successfully installed blobfile-3.0.0 deepspeed-0.4.0 fairscale-0.4.0 ftfy-6.2.3 mypy-1.11.2 mypy-extensions-1.0.0 ninja-1.11.1.1 pyDeprecate-0.3.2 pycocoevalcap-1.2 pycryptodomex-3.20.0 tensorboardX-1.8 timm-0.4.12 torchmetrics-0.7.3 torchscale-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/unilm/beit3 && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvyjO7jGYPGy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from transformers import XLMRobertaTokenizer\n",
        "from torchvision.transforms.functional import InterpolationMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7dwWcctYQyG"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/content/drive/MyDrive/unilm/beit3')\n",
        "from unilm.beit3.modeling_finetune import beit3_base_patch16_384_retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdhTguLCY-Y3",
        "outputId": "ebdfa1ad-711d-47fa-fbe4-275bf5134543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-29f0ee060d7f>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_weight_path)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BEiT3ForRetrieval(\n",
              "  (beit3): BEiT3(\n",
              "    (text_embed): TextEmbedding(64010, 768)\n",
              "    (vision_embed): VisionEmbedding(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "      (embed_positions): MutliwayEmbedding(\n",
              "        (A): PositionalEmbedding(579, 768)\n",
              "        (B): PositionalEmbedding(1024, 768)\n",
              "      )\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x EncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (k_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (v_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (q_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (out_proj): MultiwayNetwork(\n",
              "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (inner_attn_ln): MultiwayNetwork(\n",
              "              (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (self_attn_layer_norm): MultiwayNetwork(\n",
              "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "          (ffn): MultiwayNetwork(\n",
              "            (A): FeedForwardNetwork(\n",
              "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (B): FeedForwardNetwork(\n",
              "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): MultiwayNetwork(\n",
              "            (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): MultiwayNetwork(\n",
              "        (A): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (B): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (language_head): Linear(in_features=768, out_features=768, bias=False)\n",
              "  (vision_head): Linear(in_features=768, out_features=768, bias=False)\n",
              "  (criterion): ClipLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_weight_path = '/content/drive/MyDrive/beit3-retrieval-pth/beit3_base_patch16_384_f30k_retrieval.pth'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "beit3_model = beit3_base_patch16_384_retrieval(pretrained=True)\n",
        "checkpoint = torch.load(model_weight_path)\n",
        "beit3_model.load_state_dict(checkpoint['model'])\n",
        "beit3_model.to(device)\n",
        "beit3_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o18s4PpvaArk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_sentencepiece_model_for_beit3(model_path):\n",
        "    from transformers import XLMRobertaTokenizer\n",
        "    return XLMRobertaTokenizer(model_path)\n",
        "\n",
        "def to_text_tokens(text, tokenizer, max_len = 64):\n",
        "\n",
        "    tokens_orig = tokenizer.tokenize(text)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens_orig)\n",
        "    tokens = token_ids\n",
        "\n",
        "    if len(tokens) > max_len - 2:\n",
        "        tokens = tokens[:max_len - 2]\n",
        "\n",
        "    tokens = [tokenizer.bos_token_id] + tokens[:] + [tokenizer.eos_token_id]\n",
        "    num_tokens = len(tokens)\n",
        "    padding_mask = [0] * num_tokens + [1] * (max_len - num_tokens)\n",
        "    tokens_true = tokens + [tokenizer.pad_token_id] * (max_len - num_tokens)\n",
        "\n",
        "    padding_mask_tensor = torch.tensor(padding_mask).reshape(1, -1).to(device)\n",
        "    token_ids_tensor = torch.tensor(tokens_true).reshape(1, -1).to(device)\n",
        "\n",
        "    return token_ids_tensor, padding_mask_tensor\n",
        "\n",
        "def calc_text_embedding(text, tokenizer):\n",
        "    text_tokens, padding_mask = to_text_tokens(text, tokenizer)\n",
        "    text_embedding = beit3_model(text_description=text_tokens, padding_mask=padding_mask, only_infer=True)\n",
        "    return text_embedding[1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WZc-pOFaCQo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "def encode_images(image_paths, batch_size, image_size=384):\n",
        "    \"\"\"\n",
        "    Encode a list of images into feature vectors using a pre-trained model.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of image paths to be encoded.\n",
        "        batch_size (int): Number of images to process in a single batch.\n",
        "        image_size (int): Size to which each image will be resized (default is 384).\n",
        "\n",
        "    Returns:\n",
        "        video_features (list): A list of numpy arrays containing the feature vectors for each image.\n",
        "    \"\"\"\n",
        "    video_features, images = [], []\n",
        "\n",
        "    # Loop through each image path and preprocess the image\n",
        "    for image_path in image_paths:\n",
        "        # Define the image transformation pipeline\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        # Open the image, convert to RGB, and apply transformations\n",
        "        raw_image = Image.open(image_path).convert('RGB')\n",
        "        image = transform(raw_image).unsqueeze(0).to(device)\n",
        "        images.append(image)\n",
        "\n",
        "    # Concatenate all images into a single tensor\n",
        "    images = torch.cat(images, dim=0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Loop through the images in batches and encode them\n",
        "        for start_index in range(0, images.shape[0], batch_size):\n",
        "            # Process a batch of images through the model\n",
        "            image_features, _ = beit3_model(image=images[start_index:start_index+batch_size], only_infer=True)\n",
        "\n",
        "            # Normalize the feature vectors\n",
        "            image_features = normalize(image_features, p=2, dim=-1)\n",
        "\n",
        "            # Convert feature vectors to numpy arrays and store them\n",
        "            for index in range(image_features.shape[0]):\n",
        "                video_features.append(image_features[index].cpu().numpy().astype(np.float32).flatten())\n",
        "\n",
        "    # Return the list of feature vectors for all images\n",
        "    return video_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0UsbshXaLDD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def sorted_by_id(keyframe_paths):\n",
        "    id_path_keyframes = []\n",
        "\n",
        "    for keyframe_path in keyframe_paths:\n",
        "        keyframe_filename = os.path.basename(keyframe_path)\n",
        "\n",
        "        match = re.search(r'\\d+', keyframe_filename)\n",
        "        if match:\n",
        "            keyframe_id = int(match.group())  # Lấy phần số đầu tiên tìm được\n",
        "        else:\n",
        "            print(f\"Warning: {keyframe_filename} does not contain a valid ID\")\n",
        "            continue\n",
        "\n",
        "        # Thêm tuple (ID, đường dẫn) vào danh sách\n",
        "        id_path_keyframes.append((keyframe_id, keyframe_path))\n",
        "\n",
        "    # Sắp xếp danh sách theo ID\n",
        "    sorted_id_path_keyframes = sorted(id_path_keyframes, key=lambda id_path: id_path[0])\n",
        "\n",
        "    # Trả về danh sách chỉ chứa các đường dẫn (path)\n",
        "    return [id_path[1] for id_path in sorted_id_path_keyframes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94klcwCNaM_6"
      },
      "outputs": [],
      "source": [
        "# id2image_save_dir='./beit3/id2image'\n",
        "feature_save_dir=\"/content/drive/MyDrive/Frame Embedding/\"\n",
        "# if not os.path.exists(id2image_save_dir):\n",
        "#     os.makedirs(id2image_save_dir)\n",
        "if not os.path.exists(feature_save_dir):\n",
        "    os.makedirs(feature_save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_frame_path_to_id(frame_path):\n",
        "    # Tách chuỗi frame_path thành các phần tử\n",
        "    parts = frame_path.split('/')\n",
        "    filename = parts[-2]  # Lấy tên file\n",
        "    video_info = filename.split('_')  # Tách tên file bằng dấu gạch dưới\n",
        "    video_id = video_info[0] + '_' + video_info[1]  # Lấy ID video\n",
        "    frame_number = parts[-1].replace('.jpg', '').replace('frame_', '')  # Lấy số frame\n",
        "\n",
        "    # Định dạng lại frame_id với số frame đủ 5 chữ số\n",
        "    frame_id = f\"{video_id}_{frame_number.zfill(5)}\"\n",
        "    return frame_id"
      ],
      "metadata": {
        "id": "YxZszdaV6Y15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zu4kwbxaQfB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to save keyframe embeddings and paths to a JSON Lines file\n",
        "def save_to_json_lines(file_path, data):\n",
        "    with open(file_path, \"a\") as json_file:  # Open in append mode\n",
        "        for item in data:\n",
        "            json.dump(item, json_file)\n",
        "            json_file.write('\\n')\n",
        "\n",
        "# Function to process keyframes, extract embeddings, and save to JSON Lines\n",
        "def process_video_embeddings(video_folder_path, batch_size, feature_save_path):\n",
        "    \"\"\"\n",
        "    Processes all keyframes from videos in the specified folder, extracts their embeddings, and saves them to a JSON Lines file.\n",
        "\n",
        "    Args:\n",
        "        video_folder_path (str): Path to the folder containing videos.\n",
        "        batch_size (int): The batch size for encoding images.\n",
        "        feature_save_path (str): Path where the JSON Lines file will be saved.\n",
        "        encode_images (function): Function to encode images and extract embeddings.\n",
        "        sorted_by_id (function): Function to sort keyframe paths by their ID.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Ensure the file is created if it doesn't exist\n",
        "    open(feature_save_path, 'a').close()\n",
        "\n",
        "    # Loop through each subfolder in the video folder\n",
        "    for video_id in tqdm(sorted(os.listdir(video_folder_path)), desc='Processing Videos'):\n",
        "        video_id_path = os.path.join(video_folder_path, video_id)\n",
        "\n",
        "        # Check if it's a directory (i.e., a video part)\n",
        "        if os.path.isdir(video_id_path):\n",
        "            # Get and sort the keyframe paths\n",
        "            keyframe_image_paths = [os.path.join(video_id_path, keyframe_image_path) for keyframe_image_path in os.listdir(video_id_path)]\n",
        "            sorted_keyframe_image_paths = sorted_by_id(keyframe_image_paths)\n",
        "\n",
        "            # Encode the sorted keyframe images\n",
        "            video_features = encode_images(sorted_keyframe_image_paths, batch_size)\n",
        "\n",
        "            # Prepare data to be saved for the current video\n",
        "            all_frame_embeddings = []  # List to store embeddings for the current video\n",
        "\n",
        "            # Append each keyframe embedding along with its relative path to the list\n",
        "            for idx, feature in enumerate(video_features):\n",
        "                absolute_frame_path = sorted_keyframe_image_paths[idx]\n",
        "                all_frame_embeddings.append({\n",
        "                    \"frame_id\": convert_frame_path_to_id(absolute_frame_path),\n",
        "                    \"frame_embedding\": [feature.tolist()]\n",
        "                })\n",
        "\n",
        "            save_to_json_lines(feature_save_path, all_frame_embeddings)\n",
        "\n",
        "    print(f\"Frame embeddings and paths saved to {feature_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "PCa21KBD-02b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L48b99G7aUIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbc5518-2703-43ea-f8ff-0a43785f8fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing L17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Videos: 100%|██████████| 28/28 [23:29<00:00, 50.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame embeddings and paths saved to /content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/frame_embedding_L17_Beit3_rest.json\n",
            "Processing L18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Videos: 100%|██████████| 29/29 [29:55<00:00, 61.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame embeddings and paths saved to /content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/frame_embedding_L18_Beit3_rest.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(17, 19):\n",
        "        print(f'Processing L{str(i).zfill(2)}')\n",
        "        all_video_paths = f'/content/drive/MyDrive/Qualifying Round Full Frame (DONT TOUCH)/L{str(i).zfill(2)}_rest'\n",
        "        batch_size = 32\n",
        "        features_save_path = f'/content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/frame_embedding_L{str(i).zfill(2)}_Beit3_rest.json'\n",
        "        process_video_embeddings(all_video_paths, batch_size, features_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20, 21):\n",
        "        print(f'Processing L{str(i).zfill(2)}')\n",
        "        all_video_paths = f'/content/drive/MyDrive/Qualifying Round Full Frame (DONT TOUCH)/L{str(i).zfill(2)}_rest'\n",
        "        batch_size = 32\n",
        "        features_save_path = f'/content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/frame_embedding_L{str(i).zfill(2)}_Beit3_rest.json'\n",
        "        process_video_embeddings(all_video_paths, batch_size, features_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JnIh01T2eql",
        "outputId": "544cb5dd-d741-49cc-8634-0013fcd2ba2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing L20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Videos: 100%|██████████| 58/58 [30:22<00:00, 31.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame embeddings and paths saved to /content/drive/MyDrive/Frame Embedding/Frame Embeddings Of Ls Beit3/frame_embedding_L20_Beit3_rest.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_total_frames(video_folder_path):\n",
        "    \"\"\"\n",
        "    Counts the total number of frames in all videos in a folder.\n",
        "\n",
        "    Args:\n",
        "        video_folder_path (str): Path to the folder containing video subfolders.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of frames across all videos.\n",
        "    \"\"\"\n",
        "    total_frame_count = 0\n",
        "\n",
        "    # Iterate through each subfolder (each subfolder represents a video)\n",
        "    for video_id in os.listdir(video_folder_path):\n",
        "        if video_id.startswith('L'):\n",
        "            video_id_path = os.path.join(video_folder_path, video_id)\n",
        "\n",
        "            # Check if it's a directory (i.e., a video part)\n",
        "            if os.path.isdir(video_id_path):\n",
        "                # List all files (frames) in the video folder\n",
        "                frame_files = os.listdir(video_id_path)\n",
        "\n",
        "                # Count the number of frames (assuming each file is a frame image)\n",
        "                total_frame_count += len(frame_files)\n",
        "\n",
        "    return total_frame_count\n"
      ],
      "metadata": {
        "id": "fxosjd44s4ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_total_frames('/content/drive/MyDrive/Qualifying Round Full Frame (DONT TOUCH)/L18_rest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5eGf682tK_2",
        "outputId": "10aa2919-0647-45b4-cf4b-19c001d15e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18083"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}